# -*- coding: utf-8 -*-
"""Credit_card_fraud_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W-c8fGHt4omZ9dbOYXvxMVEPaDg4yoWQ

Importing the dependencies

# Data Extraction and Data Preprocessing
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt

#loading the dataset to a pandas dataframe
credit_card_data = pd.read_csv('/content/drive/MyDrive/creditcard.csv')

credit_card_data.head()

credit_card_data['Class'].value_counts()

"""Inference: Imbalanced dataset"""

#dataset information
credit_card_data.info()

#checking the number of missing values in each column
credit_card_data.isnull().sum()

"""No null values

0 ---> Normal transactions

1 ---> Fraudulent transactions
"""

legit = credit_card_data[credit_card_data.Class ==0]
fraud = credit_card_data[credit_card_data.Class ==1]

print(legit.shape)
print(fraud.shape)

"""# Data Analysis"""

#statistical measures of the data
legit.Amount.describe()

fraud.Amount.describe()

# Compare the values for both transactions

credit_card_data.groupby('Class').mean()

"""Dealing with Unbalanced Data using Undersampling

Build a sample dataset containing similar distribution of normal transactions and fraudulent transactions


number of fraudulenmt transactions are 492
"""

legit_sample = legit.sample(n=492)

"""Concatenating Two Dataframes"""

new_dataset = pd.concat([legit_sample, fraud], axis =0 )

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

"""Spliting the data into features and target"""

x = new_dataset.drop(columns='Class', axis=1)
y = new_dataset['Class']

print(x)
print(y)

"""Splitting the data into training data and testing data"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify= y, random_state =2)

"""Using stratify =y , the data with 0 and 1 will be evenly distributed in both x_train and x_test"""

print(x.shape, x_train.shape, x_test.shape)

"""# Model_Training"""

model = LogisticRegression()

# training the Logistic regression Model with Training data
model.fit(x_train, y_train)

"""Model Evaluation

Accuracy Score
"""

#accuracy on training data
x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(x_train_prediction, y_train)

print('The Accuracy on training data: ', training_data_accuracy)

# accuracy on test data
x_test_prediction = model.predict(x_test)
testing_data_accuracy = accuracy_score(x_test_prediction, y_test)

print('The Accuracy on testing data: ', testing_data_accuracy)

"""Since the Accuracy of the training data and Testing data is very similar , there is no overfitting or underfitting

Confusion Matrix
"""

cm = confusion_matrix(x_test_prediction , y_test)

sns.heatmap(cm, annot=True, fmt='g', xticklabels=['Legit', 'Fraud'], yticklabels=['Legit', 'Fraud'])
plt.ylabel('Prediction', fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix', fontsize =17)
plt.show()

"""
print(classification_report(y_test, y_pred))

this is used to get the complete metric at one place"""

precision = precision_score(y_test, x_test_prediction)
print("Precision :", precision)
recall = recall_score(y_test, x_test_prediction)
print("Recall    :", recall)
F1_score = f1_score(y_test, x_test_prediction)
print("F1-score  :", F1_score)

print(classification_report(y_test, x_test_prediction))

"""ROC Curve"""

false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, x_test_prediction, pos_label=1)

auc_score = roc_auc_score(y_test, x_test_prediction)
print(auc_score)

"""Its a high Auc Score so Model is really good"""

plt.plot(true_positive_rate,false_positive_rate,  marker='.', label='Logistic')
plt.xlabel('True Positive Rate')
plt.ylabel('False Positive Rate')
# show the legend
plt.legend()
# show the plot
plt.show()